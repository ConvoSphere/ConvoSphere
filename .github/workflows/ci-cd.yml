name: CI/CD Pipeline

on:
  push:
    branches: [ main, master ]
    paths-ignore:
      - 'docs/**'
      - 'mkdocs.yml'
      - '.github/workflows/docs.yml'
  pull_request:
    branches: [ main, master ]
    paths-ignore:
      - 'docs/**'
      - 'mkdocs.yml'
      - '.github/workflows/docs.yml'
  workflow_dispatch:

# Add permissions for GitHub script to comment on issues
permissions:
  contents: read
  issues: write
  pull-requests: write

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Quick validation (fast checks only)
  quick-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: frontend-react/package-lock.json
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ruff bandit mypy
      
      - name: Install Node.js dependencies
        run: |
          cd frontend-react
          npm ci
      
      - name: Run Python linting (warnings allowed)
        id: python-lint
        run: |
          echo "Running Python linting..."
          ruff check backend/ --output-format=json > ruff-report.json || true
          ruff format --check backend/ > ruff-format-report.json 2>&1 || true
          
          # Check if there are any critical errors (not just warnings)
          python -c "
          import json
          try:
              with open('ruff-report.json', 'r') as f:
                  data = json.load(f)
              # Only fail on critical errors, not formatting issues
              critical_errors = []
              for issue in data:
                  code = issue.get('code')
                  if code and code.startswith(('F821', 'F823', 'F841')):
                      critical_errors.append(issue)
              if critical_errors:
                  print(f'Found {len(critical_errors)} critical errors in Python linting')
                  exit(1)
              else:
                  print('No critical errors found in Python linting')
          except (FileNotFoundError, json.JSONDecodeError, KeyError) as e:
              print(f'Error processing ruff report: {e}')
              print('No critical errors found in Python linting')
          "
      
      - name: Run TypeScript linting (warnings allowed)
        id: typescript-lint
        run: |
          echo "Running TypeScript linting..."
          cd frontend-react
          npm run lint -- --format=json --output-file=eslint-report.json || true
          
          # Check if there are any errors (not just warnings)
          node -e "
          const fs = require('fs');
          try {
              const data = JSON.parse(fs.readFileSync('eslint-report.json', 'utf8'));
              const errors = data.filter(issue => issue.severity === 2);
              if (errors.length > 0) {
                  console.log('Found ' + errors.length + ' errors in TypeScript linting');
                  process.exit(1);
              } else {
                  console.log('No errors found in TypeScript linting');
              }
          } catch (e) {
              console.log('No linting issues found');
          }
          "
      
      - name: Run security checks
        run: |
          bandit -r backend/ -f json -o bandit-report.json || true
      
      - name: Run type checking (warnings allowed)
        id: type-check
        run: |
          echo "Running type checking..."
          mypy backend/ --ignore-missing-imports --json-report mypy-report.json || true
          
          # Check if there are any errors (not just warnings)
          python -c "
          import json
          try:
              with open('mypy-report.json', 'r') as f:
                  data = json.load(f)
              errors = []
              for file_data in data.values():
                  for issue in file_data:
                      if issue.get('severity') == 'error':
                          errors.append(issue)
              if errors:
                  print(f'Found {len(errors)} type errors')
                  exit(1)
              else:
                  print('No type errors found')
          except FileNotFoundError:
              print('No type checking issues found')
          "
      
      - name: Upload linting reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: linting-reports
          path: |
            ruff-report.json
            ruff-format-report.json
            eslint-report.json
            mypy-report.json
            bandit-report.json
          retention-days: 30
      
      - name: Comment on PR with linting results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v6
        with:
          script: |
            try {
              const fs = require('fs');
              let message = '## ðŸ” Linting Results\n\n';
              
              try {
                // Python linting results
                const ruffData = JSON.parse(fs.readFileSync('ruff-report.json', 'utf8'));
                const warnings = ruffData.filter(issue => !issue.code.startsWith('E') && !issue.code.startsWith('F'));
                const errors = ruffData.filter(issue => issue.code.startsWith('E') || issue.code.startsWith('F'));
                
                message += `### Python Linting\n`;
                message += `- âœ… Errors: ${errors.length}\n`;
                message += `- âš ï¸ Warnings: ${warnings.length}\n\n`;
                
                if (warnings.length > 0) {
                  message += `**Warnings found:**\n`;
                  warnings.slice(0, 10).forEach(w => {
                    message += `- ${w.code}: ${w.message} (${w.location.file}:${w.location.row})\n`;
                  });
                  if (warnings.length > 10) {
                    message += `- ... and ${warnings.length - 10} more warnings\n`;
                  }
                  message += '\n';
                }
              } catch (e) {
                message += `### Python Linting\n- âœ… No issues found\n\n`;
              }
              
              try {
                // TypeScript linting results
                const eslintData = JSON.parse(fs.readFileSync('eslint-report.json', 'utf8'));
                const warnings = eslintData.filter(issue => issue.severity === 1);
                const errors = eslintData.filter(issue => issue.severity === 2);
                
                message += `### TypeScript Linting\n`;
                message += `- âœ… Errors: ${errors.length}\n`;
                message += `- âš ï¸ Warnings: ${warnings.length}\n\n`;
                
                if (warnings.length > 0) {
                  message += `**Warnings found:**\n`;
                  warnings.slice(0, 10).forEach(w => {
                    message += `- ${w.ruleId}: ${w.message} (${w.filePath}:${w.line})\n`;
                  });
                  if (warnings.length > 10) {
                    message += `- ... and ${warnings.length - 10} more warnings\n`;
                  }
                  message += '\n';
                }
              } catch (e) {
                message += `### TypeScript Linting\n- âœ… No issues found\n\n`;
              }
              
              message += `> ðŸ’¡ **Note:** Warnings are shown for information but don't block the build. Only errors will cause the pipeline to fail.`;
              
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: message
              });
              console.log('Successfully posted linting results comment');
            } catch (error) {
              console.error('Failed to post comment:', error.message);
              // Don't fail the workflow if commenting fails
              core.setFailed('Failed to post comment to PR, but this is not a critical failure');
            }

  # Build Docker images
  build-images:
    runs-on: ubuntu-latest
    needs: quick-validation
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,prefix={{branch}}-
      
      - name: Build and push backend image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/backend/Dockerfile
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
      
      - name: Build and push frontend image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/frontend/Dockerfile
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/frontend:${{ steps.meta.outputs.version }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Deploy to staging (if staging environment exists)
  deploy-staging:
    runs-on: ubuntu-latest
    needs: build-images
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    environment: staging
    
    steps:
      - name: Deploy to staging
        run: |
          echo "Deploying to staging environment..."
          # Add your staging deployment logic here
          # This could be deploying to a staging server, Kubernetes cluster, etc.

  # Deploy to production (manual approval required)
  deploy-production:
    runs-on: ubuntu-latest
    needs: [quick-validation, build-images]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: production
    
    steps:
      - name: Deploy to production
        run: |
          echo "Deploying to production environment..."
          # Add your production deployment logic here
          # This could be deploying to a production server, Kubernetes cluster, etc.

  # Security scanning
  security-scan:
    runs-on: ubuntu-latest
    needs: quick-validation
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
      
      - name: Upload Trivy scan results to GitHub Security tab
        uses: github/codeql-action/upload-sarif@v3
        if: always()
        with:
          sarif_file: 'trivy-results.sarif'
      
      - name: Upload security scan results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: security-scan-results
          path: trivy-results.sarif
          retention-days: 30